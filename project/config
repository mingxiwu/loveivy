- Add the following to .bashrc_profile

PATH=$PATH:/Users/mwu/Applications/sbt/bin/:$SCALA_HOME/bin
SCALA_HOME=/server/scala/

# added by Anaconda 1.7.0 installer
export PATH="/server/ipython/anaconda/bin:$PATH"
#this is to avoid OOM error in sbt
export SBT_OPTS=-XX:MaxPermSize=256m

-ADD_JARS=/Users/mwu/.ivy2/local/org.edb/core_2.9.3/0.0.1/jars/core_2.9.3.jar  ./spark-shell

#clean cache
rm -r /Users/mwu/.ivy2/cache/*
rm -r /Users/mwu/.ivy2/local/*

To publish
1. what ever is put into /server/edb/core/lib will be include
2. make sure use the right spark.jar there. e.g. , copy the following to the above folder
make sure before you assembly spark jar , the /server/spark/project/Spark.build contains 

def extraAssemblySettings() = Seq(test in assembly := {}) ++ Seq(
mergeStrategy in assembly := {
case m if m.toLowerCase.endsWith("manifest.mf") => MergeStrategy.discard
case m if m.toLowerCase.matches("meta-inf.*\\.sf$") => MergeStrategy.discard
case "reference.conf" => MergeStrategy.concat
case _ => MergeStrategy.first
}
)


To launch spark 0.7.3
=======================
./run spark.deploy.master.Master 
./run spark.deploy.worker.Worker spark://127.0.0.1:7077 -p 7080 --webui-port 8082
./run spark.deploy.worker.Worker spark://127.0.0.1:7077 -p 7081 --webui-port 8083

To run spark  example:
========================
./run-example org.apache.spark.examples.SparkPi spark://127.0.0.1:7077


To package edb into a jar
=============================
1. Installed assembly plugin for sbt
~/.sbt/plugins/built.sbt
add 

addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.9.2")

2. In Build.scala, import assembly lib, and add conflict merge strategy

import sbtassembly.Plugin._
import AssemblyKeys._

++assemblySettings 

def extraAssemblySettings() = Seq(test in assembly := {}) ++ Seq(
mergeStrategy in assembly := {
case m if m.toLowerCase.endsWith("manifest.mf") => MergeStrategy.discard
case m if m.toLowerCase.matches("meta-inf.*\\.sf$") => MergeStrategy.discard
case "reference.conf" => MergeStrategy.concat
case _ => MergeStrategy.last
}
)

3. Make sure we also have spark-core-assembly-0.7.2.jar under /server/edb/core/lib/
we can generate and copy it from /server/spark/sbt/sbt assembly, then copy


4. Then run sbt assembly and it will generate 
/server/edb/core/target/scala-2.9.3/core-assembly-0.0.1.jar

5. Then, go to that folder do, java -cp ./core-assembly-0.0.1.jar edb.shell.edbMain //you need to start spark first


